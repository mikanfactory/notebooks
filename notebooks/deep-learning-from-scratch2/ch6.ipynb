{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "        \n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimeLSTMの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        \n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        \n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "            \n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "        \n",
    "        grads = [0, 0, 0] \n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "            self.dh = dh\n",
    "            return dxs\n",
    "        \n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMを使った言語モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m------------------------------------------------------------\u001b[0m\n",
      "                       \u001b[92mGPU Mode (cupy)\u001b[0m\n",
      "\u001b[92m------------------------------------------------------------\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from common.time_layers import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnnlm:\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        \n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "        \n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "    \n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n",
    "        \n",
    "    def save_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(self.params, f)\n",
    "            \n",
    "    def load_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 1327 | time 0[s] | perplexity 10000.57\n",
      "| epoch 1 |  iter 21 / 1327 | time 3[s] | perplexity 2692.27\n",
      "| epoch 1 |  iter 41 / 1327 | time 6[s] | perplexity 1252.73\n",
      "| epoch 1 |  iter 61 / 1327 | time 9[s] | perplexity 980.69\n",
      "| epoch 1 |  iter 81 / 1327 | time 12[s] | perplexity 789.74\n",
      "| epoch 1 |  iter 101 / 1327 | time 15[s] | perplexity 652.47\n",
      "| epoch 1 |  iter 121 / 1327 | time 18[s] | perplexity 639.44\n",
      "| epoch 1 |  iter 141 / 1327 | time 21[s] | perplexity 597.98\n",
      "| epoch 1 |  iter 161 / 1327 | time 24[s] | perplexity 562.75\n",
      "| epoch 1 |  iter 181 / 1327 | time 27[s] | perplexity 593.69\n",
      "| epoch 1 |  iter 201 / 1327 | time 31[s] | perplexity 488.02\n",
      "| epoch 1 |  iter 221 / 1327 | time 34[s] | perplexity 490.34\n",
      "| epoch 1 |  iter 241 / 1327 | time 37[s] | perplexity 446.82\n",
      "| epoch 1 |  iter 261 / 1327 | time 40[s] | perplexity 466.34\n",
      "| epoch 1 |  iter 281 / 1327 | time 43[s] | perplexity 448.58\n",
      "| epoch 1 |  iter 301 / 1327 | time 46[s] | perplexity 389.05\n",
      "| epoch 1 |  iter 321 / 1327 | time 49[s] | perplexity 348.44\n",
      "| epoch 1 |  iter 341 / 1327 | time 52[s] | perplexity 402.85\n",
      "| epoch 1 |  iter 361 / 1327 | time 55[s] | perplexity 406.88\n",
      "| epoch 1 |  iter 381 / 1327 | time 58[s] | perplexity 335.72\n",
      "| epoch 1 |  iter 401 / 1327 | time 61[s] | perplexity 348.34\n",
      "| epoch 1 |  iter 421 / 1327 | time 64[s] | perplexity 344.40\n",
      "| epoch 1 |  iter 441 / 1327 | time 67[s] | perplexity 337.22\n",
      "| epoch 1 |  iter 461 / 1327 | time 70[s] | perplexity 327.71\n",
      "| epoch 1 |  iter 481 / 1327 | time 73[s] | perplexity 308.86\n",
      "| epoch 1 |  iter 501 / 1327 | time 77[s] | perplexity 316.99\n",
      "| epoch 1 |  iter 521 / 1327 | time 80[s] | perplexity 305.23\n",
      "| epoch 1 |  iter 541 / 1327 | time 83[s] | perplexity 312.91\n",
      "| epoch 1 |  iter 561 / 1327 | time 86[s] | perplexity 289.60\n",
      "| epoch 1 |  iter 581 / 1327 | time 89[s] | perplexity 258.65\n",
      "| epoch 1 |  iter 601 / 1327 | time 92[s] | perplexity 336.50\n",
      "| epoch 1 |  iter 621 / 1327 | time 95[s] | perplexity 305.74\n",
      "| epoch 1 |  iter 641 / 1327 | time 98[s] | perplexity 281.66\n",
      "| epoch 1 |  iter 661 / 1327 | time 101[s] | perplexity 271.43\n",
      "| epoch 1 |  iter 681 / 1327 | time 104[s] | perplexity 226.15\n",
      "| epoch 1 |  iter 701 / 1327 | time 107[s] | perplexity 249.67\n",
      "| epoch 1 |  iter 721 / 1327 | time 111[s] | perplexity 259.40\n",
      "| epoch 1 |  iter 741 / 1327 | time 114[s] | perplexity 220.05\n",
      "| epoch 1 |  iter 761 / 1327 | time 117[s] | perplexity 231.25\n",
      "| epoch 1 |  iter 781 / 1327 | time 120[s] | perplexity 221.05\n",
      "| epoch 1 |  iter 801 / 1327 | time 123[s] | perplexity 240.18\n",
      "| epoch 1 |  iter 821 / 1327 | time 126[s] | perplexity 225.13\n",
      "| epoch 1 |  iter 841 / 1327 | time 129[s] | perplexity 227.99\n",
      "| epoch 1 |  iter 861 / 1327 | time 132[s] | perplexity 219.56\n",
      "| epoch 1 |  iter 881 / 1327 | time 135[s] | perplexity 205.82\n",
      "| epoch 1 |  iter 901 / 1327 | time 138[s] | perplexity 253.70\n",
      "| epoch 1 |  iter 921 / 1327 | time 141[s] | perplexity 225.28\n",
      "| epoch 1 |  iter 941 / 1327 | time 144[s] | perplexity 230.24\n",
      "| epoch 1 |  iter 961 / 1327 | time 148[s] | perplexity 244.28\n",
      "| epoch 1 |  iter 981 / 1327 | time 151[s] | perplexity 228.60\n",
      "| epoch 1 |  iter 1001 / 1327 | time 154[s] | perplexity 193.56\n",
      "| epoch 1 |  iter 1021 / 1327 | time 157[s] | perplexity 225.26\n",
      "| epoch 1 |  iter 1041 / 1327 | time 160[s] | perplexity 205.02\n",
      "| epoch 1 |  iter 1061 / 1327 | time 163[s] | perplexity 196.89\n",
      "| epoch 1 |  iter 1081 / 1327 | time 166[s] | perplexity 167.39\n",
      "| epoch 1 |  iter 1101 / 1327 | time 169[s] | perplexity 192.81\n",
      "| epoch 1 |  iter 1121 / 1327 | time 172[s] | perplexity 226.28\n",
      "| epoch 1 |  iter 1141 / 1327 | time 175[s] | perplexity 205.92\n",
      "| epoch 1 |  iter 1161 / 1327 | time 178[s] | perplexity 197.41\n",
      "| epoch 1 |  iter 1181 / 1327 | time 181[s] | perplexity 188.87\n",
      "| epoch 1 |  iter 1201 / 1327 | time 185[s] | perplexity 162.28\n",
      "| epoch 1 |  iter 1221 / 1327 | time 188[s] | perplexity 158.75\n",
      "| epoch 1 |  iter 1241 / 1327 | time 191[s] | perplexity 186.40\n",
      "| epoch 1 |  iter 1261 / 1327 | time 194[s] | perplexity 170.24\n",
      "| epoch 1 |  iter 1281 / 1327 | time 197[s] | perplexity 178.89\n",
      "| epoch 1 |  iter 1301 / 1327 | time 200[s] | perplexity 221.30\n",
      "| epoch 1 |  iter 1321 / 1327 | time 203[s] | perplexity 209.55\n",
      "| epoch 2 |  iter 1 / 1327 | time 204[s] | perplexity 225.93\n",
      "| epoch 2 |  iter 21 / 1327 | time 207[s] | perplexity 204.86\n",
      "| epoch 2 |  iter 41 / 1327 | time 210[s] | perplexity 188.49\n",
      "| epoch 2 |  iter 61 / 1327 | time 213[s] | perplexity 175.54\n",
      "| epoch 2 |  iter 81 / 1327 | time 217[s] | perplexity 159.07\n",
      "| epoch 2 |  iter 101 / 1327 | time 220[s] | perplexity 151.46\n",
      "| epoch 2 |  iter 121 / 1327 | time 223[s] | perplexity 158.48\n",
      "| epoch 2 |  iter 141 / 1327 | time 226[s] | perplexity 176.51\n",
      "| epoch 2 |  iter 161 / 1327 | time 229[s] | perplexity 191.32\n",
      "| epoch 2 |  iter 181 / 1327 | time 232[s] | perplexity 199.83\n",
      "| epoch 2 |  iter 201 / 1327 | time 235[s] | perplexity 183.65\n",
      "| epoch 2 |  iter 221 / 1327 | time 238[s] | perplexity 182.65\n",
      "| epoch 2 |  iter 241 / 1327 | time 241[s] | perplexity 175.88\n",
      "| epoch 2 |  iter 261 / 1327 | time 245[s] | perplexity 184.27\n",
      "| epoch 2 |  iter 281 / 1327 | time 248[s] | perplexity 183.05\n",
      "| epoch 2 |  iter 301 / 1327 | time 251[s] | perplexity 167.22\n",
      "| epoch 2 |  iter 321 / 1327 | time 254[s] | perplexity 138.49\n",
      "| epoch 2 |  iter 341 / 1327 | time 257[s] | perplexity 170.39\n",
      "| epoch 2 |  iter 361 / 1327 | time 260[s] | perplexity 194.71\n",
      "| epoch 2 |  iter 381 / 1327 | time 263[s] | perplexity 154.16\n",
      "| epoch 2 |  iter 401 / 1327 | time 266[s] | perplexity 166.91\n",
      "| epoch 2 |  iter 421 / 1327 | time 269[s] | perplexity 154.59\n",
      "| epoch 2 |  iter 441 / 1327 | time 272[s] | perplexity 162.22\n",
      "| epoch 2 |  iter 461 / 1327 | time 275[s] | perplexity 155.81\n",
      "| epoch 2 |  iter 481 / 1327 | time 279[s] | perplexity 155.57\n",
      "| epoch 2 |  iter 501 / 1327 | time 282[s] | perplexity 168.11\n",
      "| epoch 2 |  iter 521 / 1327 | time 285[s] | perplexity 171.67\n",
      "| epoch 2 |  iter 541 / 1327 | time 288[s] | perplexity 173.71\n",
      "| epoch 2 |  iter 561 / 1327 | time 291[s] | perplexity 154.44\n",
      "| epoch 2 |  iter 581 / 1327 | time 294[s] | perplexity 136.98\n",
      "| epoch 2 |  iter 601 / 1327 | time 297[s] | perplexity 190.23\n",
      "| epoch 2 |  iter 621 / 1327 | time 300[s] | perplexity 179.91\n",
      "| epoch 2 |  iter 641 / 1327 | time 303[s] | perplexity 162.91\n",
      "| epoch 2 |  iter 661 / 1327 | time 306[s] | perplexity 153.30\n",
      "| epoch 2 |  iter 681 / 1327 | time 309[s] | perplexity 128.14\n",
      "| epoch 2 |  iter 701 / 1327 | time 313[s] | perplexity 151.20\n",
      "| epoch 2 |  iter 721 / 1327 | time 316[s] | perplexity 158.14\n",
      "| epoch 2 |  iter 741 / 1327 | time 319[s] | perplexity 132.55\n",
      "| epoch 2 |  iter 761 / 1327 | time 322[s] | perplexity 130.71\n",
      "| epoch 2 |  iter 781 / 1327 | time 325[s] | perplexity 133.77\n",
      "| epoch 2 |  iter 801 / 1327 | time 328[s] | perplexity 147.03\n",
      "| epoch 2 |  iter 821 / 1327 | time 331[s] | perplexity 142.39\n",
      "| epoch 2 |  iter 841 / 1327 | time 334[s] | perplexity 143.73\n",
      "| epoch 2 |  iter 861 / 1327 | time 337[s] | perplexity 145.40\n",
      "| epoch 2 |  iter 881 / 1327 | time 340[s] | perplexity 129.84\n",
      "| epoch 2 |  iter 901 / 1327 | time 344[s] | perplexity 165.52\n",
      "| epoch 2 |  iter 921 / 1327 | time 347[s] | perplexity 146.03\n",
      "| epoch 2 |  iter 941 / 1327 | time 350[s] | perplexity 152.18\n",
      "| epoch 2 |  iter 961 / 1327 | time 353[s] | perplexity 163.07\n",
      "| epoch 2 |  iter 981 / 1327 | time 356[s] | perplexity 153.03\n",
      "| epoch 2 |  iter 1001 / 1327 | time 359[s] | perplexity 132.82\n",
      "| epoch 2 |  iter 1021 / 1327 | time 362[s] | perplexity 155.44\n",
      "| epoch 2 |  iter 1041 / 1327 | time 365[s] | perplexity 141.48\n",
      "| epoch 2 |  iter 1061 / 1327 | time 368[s] | perplexity 128.88\n",
      "| epoch 2 |  iter 1081 / 1327 | time 371[s] | perplexity 110.17\n",
      "| epoch 2 |  iter 1101 / 1327 | time 375[s] | perplexity 119.47\n",
      "| epoch 2 |  iter 1121 / 1327 | time 378[s] | perplexity 150.97\n",
      "| epoch 2 |  iter 1141 / 1327 | time 381[s] | perplexity 140.69\n",
      "| epoch 2 |  iter 1161 / 1327 | time 384[s] | perplexity 131.34\n",
      "| epoch 2 |  iter 1181 / 1327 | time 387[s] | perplexity 133.26\n",
      "| epoch 2 |  iter 1201 / 1327 | time 390[s] | perplexity 111.71\n",
      "| epoch 2 |  iter 1221 / 1327 | time 393[s] | perplexity 108.60\n",
      "| epoch 2 |  iter 1241 / 1327 | time 396[s] | perplexity 128.79\n",
      "| epoch 2 |  iter 1261 / 1327 | time 399[s] | perplexity 123.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 2 |  iter 1281 / 1327 | time 402[s] | perplexity 122.00\n",
      "| epoch 2 |  iter 1301 / 1327 | time 405[s] | perplexity 156.69\n",
      "| epoch 2 |  iter 1321 / 1327 | time 409[s] | perplexity 153.41\n",
      "| epoch 3 |  iter 1 / 1327 | time 410[s] | perplexity 162.60\n",
      "| epoch 3 |  iter 21 / 1327 | time 413[s] | perplexity 143.30\n",
      "| epoch 3 |  iter 41 / 1327 | time 416[s] | perplexity 134.40\n",
      "| epoch 3 |  iter 61 / 1327 | time 419[s] | perplexity 125.89\n",
      "| epoch 3 |  iter 81 / 1327 | time 422[s] | perplexity 116.29\n",
      "| epoch 3 |  iter 101 / 1327 | time 425[s] | perplexity 105.39\n",
      "| epoch 3 |  iter 121 / 1327 | time 428[s] | perplexity 115.32\n",
      "| epoch 3 |  iter 141 / 1327 | time 431[s] | perplexity 125.50\n",
      "| epoch 3 |  iter 161 / 1327 | time 434[s] | perplexity 141.64\n",
      "| epoch 3 |  iter 181 / 1327 | time 437[s] | perplexity 149.75\n",
      "| epoch 3 |  iter 201 / 1327 | time 440[s] | perplexity 141.16\n",
      "| epoch 3 |  iter 221 / 1327 | time 443[s] | perplexity 139.97\n",
      "| epoch 3 |  iter 241 / 1327 | time 447[s] | perplexity 133.92\n",
      "| epoch 3 |  iter 261 / 1327 | time 450[s] | perplexity 138.28\n",
      "| epoch 3 |  iter 281 / 1327 | time 453[s] | perplexity 141.20\n",
      "| epoch 3 |  iter 301 / 1327 | time 456[s] | perplexity 123.97\n",
      "| epoch 3 |  iter 321 / 1327 | time 459[s] | perplexity 101.86\n",
      "| epoch 3 |  iter 341 / 1327 | time 462[s] | perplexity 122.88\n",
      "| epoch 3 |  iter 361 / 1327 | time 465[s] | perplexity 152.08\n",
      "| epoch 3 |  iter 381 / 1327 | time 468[s] | perplexity 116.14\n",
      "| epoch 3 |  iter 401 / 1327 | time 471[s] | perplexity 128.40\n",
      "| epoch 3 |  iter 421 / 1327 | time 474[s] | perplexity 113.95\n",
      "| epoch 3 |  iter 441 / 1327 | time 477[s] | perplexity 122.78\n",
      "| epoch 3 |  iter 461 / 1327 | time 480[s] | perplexity 116.96\n",
      "| epoch 3 |  iter 481 / 1327 | time 483[s] | perplexity 119.80\n",
      "| epoch 3 |  iter 501 / 1327 | time 486[s] | perplexity 127.35\n",
      "| epoch 3 |  iter 521 / 1327 | time 490[s] | perplexity 136.99\n",
      "| epoch 3 |  iter 541 / 1327 | time 493[s] | perplexity 134.87\n",
      "| epoch 3 |  iter 561 / 1327 | time 496[s] | perplexity 118.48\n",
      "| epoch 3 |  iter 581 / 1327 | time 499[s] | perplexity 104.59\n",
      "| epoch 3 |  iter 601 / 1327 | time 502[s] | perplexity 150.64\n",
      "| epoch 3 |  iter 621 / 1327 | time 505[s] | perplexity 142.11\n",
      "| epoch 3 |  iter 641 / 1327 | time 508[s] | perplexity 127.41\n",
      "| epoch 3 |  iter 661 / 1327 | time 511[s] | perplexity 119.54\n",
      "| epoch 3 |  iter 681 / 1327 | time 514[s] | perplexity 99.88\n",
      "| epoch 3 |  iter 701 / 1327 | time 517[s] | perplexity 119.15\n",
      "| epoch 3 |  iter 721 / 1327 | time 520[s] | perplexity 126.08\n",
      "| epoch 3 |  iter 741 / 1327 | time 523[s] | perplexity 106.39\n",
      "| epoch 3 |  iter 761 / 1327 | time 526[s] | perplexity 102.80\n",
      "| epoch 3 |  iter 781 / 1327 | time 529[s] | perplexity 105.44\n",
      "| epoch 3 |  iter 801 / 1327 | time 532[s] | perplexity 115.52\n",
      "| epoch 3 |  iter 821 / 1327 | time 535[s] | perplexity 115.93\n",
      "| epoch 3 |  iter 841 / 1327 | time 539[s] | perplexity 114.74\n",
      "| epoch 3 |  iter 861 / 1327 | time 542[s] | perplexity 119.88\n",
      "| epoch 3 |  iter 881 / 1327 | time 545[s] | perplexity 105.36\n",
      "| epoch 3 |  iter 901 / 1327 | time 548[s] | perplexity 131.95\n",
      "| epoch 3 |  iter 921 / 1327 | time 551[s] | perplexity 117.74\n",
      "| epoch 3 |  iter 941 / 1327 | time 554[s] | perplexity 126.88\n",
      "| epoch 3 |  iter 961 / 1327 | time 557[s] | perplexity 130.93\n",
      "| epoch 3 |  iter 981 / 1327 | time 560[s] | perplexity 122.41\n",
      "| epoch 3 |  iter 1001 / 1327 | time 563[s] | perplexity 110.75\n",
      "| epoch 3 |  iter 1021 / 1327 | time 566[s] | perplexity 128.62\n",
      "| epoch 3 |  iter 1041 / 1327 | time 569[s] | perplexity 118.71\n",
      "| epoch 3 |  iter 1061 / 1327 | time 572[s] | perplexity 103.19\n",
      "| epoch 3 |  iter 1081 / 1327 | time 575[s] | perplexity 88.32\n",
      "| epoch 3 |  iter 1101 / 1327 | time 579[s] | perplexity 93.75\n",
      "| epoch 3 |  iter 1121 / 1327 | time 582[s] | perplexity 120.60\n",
      "| epoch 3 |  iter 1141 / 1327 | time 585[s] | perplexity 112.49\n",
      "| epoch 3 |  iter 1161 / 1327 | time 588[s] | perplexity 105.64\n",
      "| epoch 3 |  iter 1181 / 1327 | time 591[s] | perplexity 110.76\n",
      "| epoch 3 |  iter 1201 / 1327 | time 594[s] | perplexity 93.66\n",
      "| epoch 3 |  iter 1221 / 1327 | time 597[s] | perplexity 88.19\n",
      "| epoch 3 |  iter 1241 / 1327 | time 600[s] | perplexity 105.03\n",
      "| epoch 3 |  iter 1261 / 1327 | time 603[s] | perplexity 105.12\n",
      "| epoch 3 |  iter 1281 / 1327 | time 606[s] | perplexity 100.12\n",
      "| epoch 3 |  iter 1301 / 1327 | time 609[s] | perplexity 128.37\n",
      "| epoch 3 |  iter 1321 / 1327 | time 612[s] | perplexity 126.68\n",
      "| epoch 4 |  iter 1 / 1327 | time 613[s] | perplexity 135.32\n",
      "| epoch 4 |  iter 21 / 1327 | time 616[s] | perplexity 122.70\n",
      "| epoch 4 |  iter 41 / 1327 | time 619[s] | perplexity 106.78\n",
      "| epoch 4 |  iter 61 / 1327 | time 623[s] | perplexity 106.42\n",
      "| epoch 4 |  iter 81 / 1327 | time 626[s] | perplexity 95.99\n",
      "| epoch 4 |  iter 101 / 1327 | time 629[s] | perplexity 86.06\n",
      "| epoch 4 |  iter 121 / 1327 | time 632[s] | perplexity 95.54\n",
      "| epoch 4 |  iter 141 / 1327 | time 635[s] | perplexity 102.77\n",
      "| epoch 4 |  iter 161 / 1327 | time 638[s] | perplexity 117.72\n",
      "| epoch 4 |  iter 181 / 1327 | time 641[s] | perplexity 129.18\n",
      "| epoch 4 |  iter 201 / 1327 | time 644[s] | perplexity 120.80\n",
      "| epoch 4 |  iter 221 / 1327 | time 647[s] | perplexity 121.43\n",
      "| epoch 4 |  iter 241 / 1327 | time 650[s] | perplexity 115.65\n",
      "| epoch 4 |  iter 261 / 1327 | time 653[s] | perplexity 114.61\n",
      "| epoch 4 |  iter 281 / 1327 | time 656[s] | perplexity 120.68\n",
      "| epoch 4 |  iter 301 / 1327 | time 660[s] | perplexity 104.86\n",
      "| epoch 4 |  iter 321 / 1327 | time 663[s] | perplexity 83.71\n",
      "| epoch 4 |  iter 341 / 1327 | time 666[s] | perplexity 100.06\n",
      "| epoch 4 |  iter 361 / 1327 | time 669[s] | perplexity 127.81\n",
      "| epoch 4 |  iter 381 / 1327 | time 672[s] | perplexity 98.78\n",
      "| epoch 4 |  iter 401 / 1327 | time 675[s] | perplexity 110.46\n",
      "| epoch 4 |  iter 421 / 1327 | time 678[s] | perplexity 94.34\n",
      "| epoch 4 |  iter 441 / 1327 | time 681[s] | perplexity 102.38\n",
      "| epoch 4 |  iter 461 / 1327 | time 684[s] | perplexity 99.44\n",
      "| epoch 4 |  iter 481 / 1327 | time 688[s] | perplexity 102.33\n",
      "| epoch 4 |  iter 501 / 1327 | time 691[s] | perplexity 108.56\n",
      "| epoch 4 |  iter 521 / 1327 | time 694[s] | perplexity 117.46\n",
      "| epoch 4 |  iter 541 / 1327 | time 697[s] | perplexity 112.42\n",
      "| epoch 4 |  iter 561 / 1327 | time 700[s] | perplexity 102.93\n",
      "| epoch 4 |  iter 581 / 1327 | time 703[s] | perplexity 89.61\n",
      "| epoch 4 |  iter 601 / 1327 | time 706[s] | perplexity 127.93\n",
      "| epoch 4 |  iter 621 / 1327 | time 709[s] | perplexity 121.09\n",
      "| epoch 4 |  iter 641 / 1327 | time 713[s] | perplexity 110.40\n",
      "| epoch 4 |  iter 661 / 1327 | time 716[s] | perplexity 102.88\n",
      "| epoch 4 |  iter 681 / 1327 | time 719[s] | perplexity 84.75\n",
      "| epoch 4 |  iter 701 / 1327 | time 722[s] | perplexity 102.22\n",
      "| epoch 4 |  iter 721 / 1327 | time 725[s] | perplexity 108.02\n",
      "| epoch 4 |  iter 741 / 1327 | time 728[s] | perplexity 94.69\n",
      "| epoch 4 |  iter 761 / 1327 | time 731[s] | perplexity 88.04\n",
      "| epoch 4 |  iter 781 / 1327 | time 734[s] | perplexity 88.07\n",
      "| epoch 4 |  iter 801 / 1327 | time 737[s] | perplexity 99.60\n",
      "| epoch 4 |  iter 821 / 1327 | time 740[s] | perplexity 102.40\n",
      "| epoch 4 |  iter 841 / 1327 | time 743[s] | perplexity 98.73\n",
      "| epoch 4 |  iter 861 / 1327 | time 746[s] | perplexity 104.81\n",
      "| epoch 4 |  iter 881 / 1327 | time 750[s] | perplexity 91.10\n",
      "| epoch 4 |  iter 901 / 1327 | time 753[s] | perplexity 114.65\n",
      "| epoch 4 |  iter 921 / 1327 | time 756[s] | perplexity 101.88\n",
      "| epoch 4 |  iter 941 / 1327 | time 759[s] | perplexity 111.85\n",
      "| epoch 4 |  iter 961 / 1327 | time 762[s] | perplexity 111.58\n",
      "| epoch 4 |  iter 981 / 1327 | time 765[s] | perplexity 106.34\n",
      "| epoch 4 |  iter 1001 / 1327 | time 768[s] | perplexity 98.36\n",
      "| epoch 4 |  iter 1021 / 1327 | time 771[s] | perplexity 113.22\n",
      "| epoch 4 |  iter 1041 / 1327 | time 774[s] | perplexity 103.77\n",
      "| epoch 4 |  iter 1061 / 1327 | time 777[s] | perplexity 89.11\n",
      "| epoch 4 |  iter 1081 / 1327 | time 780[s] | perplexity 78.89\n",
      "| epoch 4 |  iter 1101 / 1327 | time 783[s] | perplexity 78.55\n",
      "| epoch 4 |  iter 1121 / 1327 | time 787[s] | perplexity 103.27\n",
      "| epoch 4 |  iter 1141 / 1327 | time 790[s] | perplexity 98.37\n",
      "| epoch 4 |  iter 1161 / 1327 | time 793[s] | perplexity 90.90\n",
      "| epoch 4 |  iter 1181 / 1327 | time 796[s] | perplexity 96.24\n",
      "| epoch 4 |  iter 1201 / 1327 | time 799[s] | perplexity 83.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 4 |  iter 1221 / 1327 | time 802[s] | perplexity 75.51\n",
      "| epoch 4 |  iter 1241 / 1327 | time 805[s] | perplexity 91.64\n",
      "| epoch 4 |  iter 1261 / 1327 | time 808[s] | perplexity 93.20\n",
      "| epoch 4 |  iter 1281 / 1327 | time 811[s] | perplexity 90.50\n",
      "| epoch 4 |  iter 1301 / 1327 | time 814[s] | perplexity 109.92\n",
      "| epoch 4 |  iter 1321 / 1327 | time 817[s] | perplexity 109.30\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating perplexity ...\n",
      "234 / 235\n",
      "test_perplexity:  136.16937\n"
     ]
    }
   ],
   "source": [
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('test_perplexity: ', ppl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### より良いRNNLMの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "from common.np import *\n",
    "from common.base_model import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650, hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)\n",
    "        ]\n",
    "        \n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "        \n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def predict(self, xs, train_flag=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flag = train_flag\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "    \n",
    "    def forward(self, xs, ts, train_flag=True):\n",
    "        score = self.predict(xs, train_flag)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import config\n",
    "config.GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from better_rnnlm import BetterRnnlm\n",
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 1327 | time 0[s] | perplexity 10000.64\n",
      "| epoch 1 |  iter 21 / 1327 | time 6[s] | perplexity 3469.68\n",
      "| epoch 1 |  iter 41 / 1327 | time 12[s] | perplexity 1748.32\n",
      "| epoch 1 |  iter 61 / 1327 | time 18[s] | perplexity 1250.91\n",
      "| epoch 1 |  iter 81 / 1327 | time 25[s] | perplexity 1089.88\n",
      "| epoch 1 |  iter 101 / 1327 | time 31[s] | perplexity 850.37\n",
      "| epoch 1 |  iter 121 / 1327 | time 37[s] | perplexity 816.39\n",
      "| epoch 1 |  iter 141 / 1327 | time 44[s] | perplexity 725.37\n",
      "| epoch 1 |  iter 161 / 1327 | time 50[s] | perplexity 711.16\n",
      "| epoch 1 |  iter 181 / 1327 | time 56[s] | perplexity 692.72\n",
      "| epoch 1 |  iter 201 / 1327 | time 62[s] | perplexity 587.03\n",
      "| epoch 1 |  iter 221 / 1327 | time 69[s] | perplexity 586.49\n",
      "| epoch 1 |  iter 241 / 1327 | time 75[s] | perplexity 537.05\n",
      "| epoch 1 |  iter 261 / 1327 | time 81[s] | perplexity 535.62\n",
      "| epoch 1 |  iter 281 / 1327 | time 87[s] | perplexity 532.00\n",
      "| epoch 1 |  iter 301 / 1327 | time 93[s] | perplexity 456.87\n",
      "| epoch 1 |  iter 321 / 1327 | time 100[s] | perplexity 398.91\n",
      "| epoch 1 |  iter 341 / 1327 | time 106[s] | perplexity 453.57\n",
      "| epoch 1 |  iter 361 / 1327 | time 112[s] | perplexity 474.94\n",
      "| epoch 1 |  iter 381 / 1327 | time 119[s] | perplexity 388.66\n",
      "| epoch 1 |  iter 401 / 1327 | time 125[s] | perplexity 399.50\n",
      "| epoch 1 |  iter 421 / 1327 | time 131[s] | perplexity 401.30\n",
      "| epoch 1 |  iter 441 / 1327 | time 137[s] | perplexity 380.06\n",
      "| epoch 1 |  iter 461 / 1327 | time 144[s] | perplexity 374.71\n",
      "| epoch 1 |  iter 481 / 1327 | time 150[s] | perplexity 349.88\n",
      "| epoch 1 |  iter 501 / 1327 | time 156[s] | perplexity 357.25\n",
      "| epoch 1 |  iter 521 / 1327 | time 163[s] | perplexity 344.98\n",
      "| epoch 1 |  iter 541 / 1327 | time 169[s] | perplexity 359.56\n",
      "| epoch 1 |  iter 561 / 1327 | time 175[s] | perplexity 321.33\n",
      "| epoch 1 |  iter 581 / 1327 | time 182[s] | perplexity 293.64\n",
      "| epoch 1 |  iter 601 / 1327 | time 188[s] | perplexity 376.73\n",
      "| epoch 1 |  iter 621 / 1327 | time 194[s] | perplexity 350.59\n",
      "| epoch 1 |  iter 641 / 1327 | time 200[s] | perplexity 315.16\n",
      "| epoch 1 |  iter 661 / 1327 | time 206[s] | perplexity 300.32\n",
      "| epoch 1 |  iter 681 / 1327 | time 213[s] | perplexity 253.60\n",
      "| epoch 1 |  iter 701 / 1327 | time 219[s] | perplexity 279.21\n",
      "| epoch 1 |  iter 721 / 1327 | time 225[s] | perplexity 288.54\n",
      "| epoch 1 |  iter 741 / 1327 | time 232[s] | perplexity 248.87\n",
      "| epoch 1 |  iter 761 / 1327 | time 238[s] | perplexity 260.35\n",
      "| epoch 1 |  iter 781 / 1327 | time 244[s] | perplexity 247.64\n",
      "| epoch 1 |  iter 801 / 1327 | time 250[s] | perplexity 268.60\n",
      "| epoch 1 |  iter 821 / 1327 | time 256[s] | perplexity 252.09\n",
      "| epoch 1 |  iter 841 / 1327 | time 263[s] | perplexity 256.21\n",
      "| epoch 1 |  iter 861 / 1327 | time 269[s] | perplexity 248.75\n",
      "| epoch 1 |  iter 881 / 1327 | time 275[s] | perplexity 230.13\n",
      "| epoch 1 |  iter 901 / 1327 | time 281[s] | perplexity 281.20\n",
      "| epoch 1 |  iter 921 / 1327 | time 288[s] | perplexity 256.92\n",
      "| epoch 1 |  iter 941 / 1327 | time 294[s] | perplexity 258.83\n",
      "| epoch 1 |  iter 961 / 1327 | time 300[s] | perplexity 275.99\n",
      "| epoch 1 |  iter 981 / 1327 | time 306[s] | perplexity 259.20\n",
      "| epoch 1 |  iter 1001 / 1327 | time 313[s] | perplexity 216.66\n",
      "| epoch 1 |  iter 1021 / 1327 | time 319[s] | perplexity 254.06\n",
      "| epoch 1 |  iter 1041 / 1327 | time 325[s] | perplexity 232.01\n",
      "| epoch 1 |  iter 1061 / 1327 | time 331[s] | perplexity 219.59\n",
      "| epoch 1 |  iter 1081 / 1327 | time 338[s] | perplexity 189.41\n",
      "| epoch 1 |  iter 1101 / 1327 | time 344[s] | perplexity 216.03\n",
      "| epoch 1 |  iter 1121 / 1327 | time 350[s] | perplexity 255.97\n",
      "| epoch 1 |  iter 1141 / 1327 | time 357[s] | perplexity 230.82\n",
      "| epoch 1 |  iter 1161 / 1327 | time 363[s] | perplexity 221.67\n",
      "| epoch 1 |  iter 1181 / 1327 | time 369[s] | perplexity 208.58\n",
      "| epoch 1 |  iter 1201 / 1327 | time 375[s] | perplexity 182.73\n",
      "| epoch 1 |  iter 1221 / 1327 | time 381[s] | perplexity 180.57\n",
      "| epoch 1 |  iter 1241 / 1327 | time 388[s] | perplexity 211.50\n",
      "| epoch 1 |  iter 1261 / 1327 | time 394[s] | perplexity 191.13\n",
      "| epoch 1 |  iter 1281 / 1327 | time 400[s] | perplexity 198.41\n",
      "| epoch 1 |  iter 1301 / 1327 | time 406[s] | perplexity 247.04\n",
      "| epoch 1 |  iter 1321 / 1327 | time 413[s] | perplexity 233.71\n",
      "evaluating perplexity ...\n",
      "209 / 210\n",
      "test_perplexity:  201.9888\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Broadcasting failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0d3450165bb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/notebooks/notebooks/deep-learning-from-scratch2/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# 勾配を求め、パラメータを更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 共有された重みを1つに集約\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/notebooks/notebooks/deep-learning-from-scratch2/better_rnnlm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs, ts, train_flg)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/notebooks/notebooks/deep-learning-from-scratch2/better_rnnlm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, xs, train_flg)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/notebooks/notebooks/deep-learning-from-scratch2/common/time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/notebooks/notebooks/deep-learning-from-scratch2/common/time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h_prev, c_prev)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.ndarray.__add__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy.core._kernel.ufunc.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.broadcast.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Broadcasting failed"
     ]
    }
   ],
   "source": [
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size, time_size=time_size, max_grad=max_grad)\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('test_perplexity: ', ppl)\n",
    "    \n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "        model.reset_state()\n",
    "        print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "うごごごご...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
